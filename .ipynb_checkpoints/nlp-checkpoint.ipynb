{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import data_utils as du\n",
    "import evaluation as ev\n",
    "from naive_bayes import NaiveBayesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:data_utils:Successfully read 1000 NEG files\n",
      "INFO:data_utils:Successfully read 1000 POS files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NEG_FILE_LIST = du.load_data('NEG')\n",
    "POS_FILE_LIST = du.load_data('POS')\n",
    "\n",
    "neg_train_data = NEG_FILE_LIST[:900]\n",
    "neg_test_data = NEG_FILE_LIST[900:]\n",
    "\n",
    "pos_train_data = POS_FILE_LIST[:900]\n",
    "pos_test_data = POS_FILE_LIST[900:]\n",
    "\n",
    "training_data = {\"pos\": pos_train_data, \"neg\": neg_train_data}\n",
    "test_data = neg_test_data + pos_test_data\n",
    "test_targets = [0 for _ in range(len(neg_test_data))] +  [1 for _ in range(len(pos_test_data))]\n",
    "test_targets[:2] + test_targets[100:102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def eval_nb(training_data, test_data, models, smoothing=0):\n",
    "    nb = NaiveBayesClassifier(models=models, smoothing=smoothing)\n",
    "    nb.train(training_data)\n",
    "    \n",
    "    return nb.predict(test_data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:naive_bayes:Created Naive Bayes classifer with: models=[(1, 4)], smoothing=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = eval_nb(training_data, test_data, models=[(1, 4)], smoothing=0)\n",
    "np.mean(predictions == test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:naive_bayes:Created Naive Bayes classifer with: models=[(2, 7)], smoothing=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.76"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = eval_nb(training_data, test_data, models=[(2, 7)], smoothing=0)\n",
    "np.mean(predictions == test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:naive_bayes:Created Naive Bayes classifer with: models=[(1, 4), (2, 7)], smoothing=0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = eval_nb(training_data, test_data, models=[(1, 4), (2, 7)], smoothing=0)\n",
    "np.mean(predictions == test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:naive_bayes:Created Naive Bayes classifer with: models=[(1, 4)], smoothing=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsA = eval_nb(training_data, test_data, models=[(1, 4)], smoothing=1)\n",
    "np.mean(predictionsA == test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:naive_bayes:Created Naive Bayes classifer with: models=[(2, 7)], smoothing=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.755"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionsB = eval_nb(training_data, test_data, models=[(2, 7)], smoothing=1)\n",
    "np.mean(predictionsB == test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:naive_bayes:Created Naive Bayes classifer with: models=[(1, 4), (2, 7)], smoothing=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = eval_nb(training_data, test_data, models=[(1, 4), (2, 7)], smoothing=1)\n",
    "np.mean(predictions == test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# # Study how smoothing affects acc\n",
    "\n",
    "# smoothing_accs = []\n",
    "# log_smoothings = np.linspace(-7, 4, 30)\n",
    "# smoothings = np.power(10, log_smoothings)\n",
    "\n",
    "# for smoothing in tqdm(smoothings, \"Computing smoothing accuracies\"):\n",
    "#     predictions = eval_nb(training_data, test_data, models=[(1, 4)], smoothing=smoothing)\n",
    "#     smoothing_accs.append(np.mean(predictions == test_targets))\n",
    "# smoothing_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# from matplotlib.pyplot import figure\n",
    "\n",
    "# figure(num=None, figsize=(10, 4), dpi=80, facecolor='w', edgecolor='k')\n",
    "# plt.plot(log_smoothings, smoothing_accs)\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Log smoothing value')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model_smooth = [\n",
    "    ([(1, 4)], 0), ([(1, 4)], 1),\n",
    "    ([(2, 7)], 0), ([(2, 7)], 1),\n",
    "    ([(1, 4), (2, 7)], 0), ([(1, 4), (2, 7)], 1)\n",
    "]\n",
    "p_vals = np.zeros((6, 6))\n",
    "accs = np.zeros(6)\n",
    "for i, (modelA, smoothA) in tqdm(enumerate(model_smooth), \"Going over i axis\"):\n",
    "    predictionsA = eval_nb(training_data, test_data, models=modelA, smoothing=smoothA)\n",
    "    accA = np.mean(predictionsA == test_targets)\n",
    "    accs[i] = accA\n",
    "    for j, (modelB, smoothB) in enumerate(model_smooth):\n",
    "        predictionsB = eval_nb(training_data, test_data, models=modelB, smoothing=smoothB)\n",
    "        p_value = ev.sign_test(predictionsA, predictionsB, test_targets)\n",
    "        \n",
    "        p_vals[i, j] = p_value\n",
    "\n",
    "print(accs)\n",
    "print(p_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round Robin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_rr_folds(neg_file_list=NEG_FILE_LIST, pos_file_list=POS_FILE_LIST):\n",
    "    neg_folds = [neg_file_list[k::10] for k in range(10)]\n",
    "    pos_folds = [pos_file_list[k::10] for k in range(10)]\n",
    "    \n",
    "    return neg_folds, pos_folds\n",
    "\n",
    "\n",
    "def nb_process_fold_k(neg_folds, pos_folds, k):\n",
    "    neg_train_data = [file for fold in (neg_folds[:k] + neg_folds[k + 1:]) for file in fold]\n",
    "    neg_test_data = neg_folds[k]\n",
    "\n",
    "    pos_train_data = [file for fold in (pos_folds[:k] + pos_folds[k + 1:]) for file in fold]\n",
    "    pos_test_data = pos_folds[k]\n",
    "\n",
    "    training_data = {\"pos\": pos_train_data, \"neg\": neg_train_data}\n",
    "    test_data = neg_test_data + pos_test_data\n",
    "    test_targets = [0 for _ in range(len(neg_test_data))] +  [1 for _ in range(len(pos_test_data))]\n",
    "\n",
    "    return training_data, test_data, test_targets\n",
    "\n",
    "\n",
    "def get_cv_accs(model,  neg_folds, pos_folds, smoothing=0):\n",
    "    accuracies = []\n",
    "    for k in range(len(neg_folds)):\n",
    "        training_data, test_data, test_targets = nb_process_fold_k(neg_folds=neg_folds, pos_folds=pos_folds, k=k)\n",
    "        predictions = eval_nb(training_data, test_data, models=model, smoothing=smoothing)\n",
    "        accuracy = np.mean(predictions == test_targets)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "neg_folds, pos_folds = get_rr_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For [(1, 4)] sm 0 : \n",
      "\t [0.765, 0.82, 0.775, 0.835, 0.78, 0.82, 0.82, 0.785, 0.835, 0.82] \n",
      "\t Variance 0.0006222499999999986\n",
      "For [(2, 7)] sm 0 : \n",
      "\t [0.7, 0.715, 0.755, 0.79, 0.675, 0.725, 0.765, 0.77, 0.77, 0.73] \n",
      "\t Variance 0.0011922500000000006\n",
      "For [(1, 4), (2, 7)] sm 0 : \n",
      "\t [0.765, 0.815, 0.77, 0.815, 0.74, 0.845, 0.79, 0.805, 0.82, 0.805] \n",
      "\t Variance 0.0008659999999999993\n",
      "For [(1, 4)] sm 1 : \n",
      "\t [0.76, 0.835, 0.79, 0.835, 0.77, 0.83, 0.81, 0.78, 0.815, 0.815] \n",
      "\t Variance 0.0006739999999999988\n",
      "For [(2, 7)] sm 1 : \n",
      "\t [0.715, 0.755, 0.755, 0.755, 0.7, 0.785, 0.78, 0.79, 0.755, 0.74] \n",
      "\t Variance 0.0007560000000000012\n",
      "For [(1, 4), (2, 7)] sm 1 : \n",
      "\t [0.77, 0.82, 0.765, 0.825, 0.745, 0.82, 0.825, 0.8, 0.835, 0.815] \n",
      "\t Variance 0.0008609999999999987\n",
      "[[0.765, 0.82, 0.775, 0.835, 0.78, 0.82, 0.82, 0.785, 0.835, 0.82], [0.7, 0.715, 0.755, 0.79, 0.675, 0.725, 0.765, 0.77, 0.77, 0.73], [0.765, 0.815, 0.77, 0.815, 0.74, 0.845, 0.79, 0.805, 0.82, 0.805], [0.76, 0.835, 0.79, 0.835, 0.77, 0.83, 0.81, 0.78, 0.815, 0.815], [0.715, 0.755, 0.755, 0.755, 0.7, 0.785, 0.78, 0.79, 0.755, 0.74], [0.77, 0.82, 0.765, 0.825, 0.745, 0.82, 0.825, 0.8, 0.835, 0.815]]\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy list for the models\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "compared_models = [\n",
    "    ([(1, 4)], 0), \n",
    "    ([(2, 7)], 0), \n",
    "    ([(1, 4), (2, 7)], 0),\n",
    "    ([(1, 4)], 1), \n",
    "    ([(2, 7)], 1),\n",
    "    ([(1, 4), (2, 7)], 1)\n",
    "]\n",
    "nb_accs = list()\n",
    "for i, (model, smooth) in enumerate(compared_models):\n",
    "    accuracies = get_cv_accs(model=model, smoothing=smooth, neg_folds=neg_folds,\n",
    "                                                       pos_folds=pos_folds)\n",
    "    nb_accs.append(accuracies)\n",
    "    print(\"For {0} sm {1} : \\n\\t {2} \\n\\t Variance {3}\".format(model, smooth, accuracies, np.var(accuracies)))\n",
    "\n",
    "print(nb_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan 0.00 0.22 0.69 0.00 0.43]\n",
      " [0.00 nan 0.00 0.00 0.14 0.00]\n",
      " [0.22 0.00 nan 0.26 0.00 0.33]\n",
      " [0.69 0.00 0.26 nan 0.00 0.73]\n",
      " [0.00 0.14 0.00 0.00 nan 0.00]\n",
      " [0.43 0.00 0.33 0.73 0.00 nan]]\n",
      "[[nan 6.34 1.33 0.41 5.56 0.83]\n",
      " [-6.34 nan -5.30 -5.82 -1.60 -6.60]\n",
      " [-1.33 5.30 nan -1.21 6.20 -1.02]\n",
      " [-0.41 5.82 1.21 nan 5.71 0.36]\n",
      " [-5.56 1.60 -6.20 -5.71 nan -6.19]\n",
      " [-0.83 6.60 1.02 -0.36 6.19 nan]]\n"
     ]
    }
   ],
   "source": [
    "# Paired t-test\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "p_vals = np.zeros((6, 6))\n",
    "t_stats = np.zeros((6, 6))\n",
    "\n",
    "for i in range(6):    \n",
    "    for j in range(6):\n",
    "        accA = nb_accs[i]\n",
    "        accB = nb_accs[j]\n",
    "        t, p = ttest_rel(accA, accB)\n",
    "        p_vals[i, j] = p\n",
    "        t_stats[i, j] = t\n",
    "        \n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})\n",
    "print(p_vals)\n",
    "print(t_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from data_utils import load_untagged_data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "neg_file_list = load_untagged_data('NEG')\n",
    "pos_file_list = load_untagged_data('POS')\n",
    "neg_folds_svm, pos_folds_svm = get_rr_folds(neg_file_list, pos_file_list)\n",
    "\n",
    "train_data_folds_svm = [neg + pos for neg, pos in zip(neg_folds[1:], pos_folds[1:])]\n",
    "train_target_folds_svm = [[0 for _ in range(len(neg))] + [1 for _ in range(len(pos))] for neg, pos in zip(neg_folds[1:], pos_folds[1:])]\n",
    "\n",
    "test_data_svm = neg_folds[0] + pos_folds[0]\n",
    "test_targets_svm = [0 for _ in range(len(neg_folds[0]))] + [1 for _ in range(len(pos_folds[0]))]\n",
    "\n",
    "assert(len(train_data_folds_svm) == len(train_target_folds_svm) == 9)\n",
    "assert(len(test_data_svm) == len(test_targets_svm) == 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.795, 0.795, 0.815, 0.77, 0.825, 0.835, 0.76, 0.82, 0.795], [0.745, 0.76, 0.785, 0.69, 0.735, 0.765, 0.77, 0.76, 0.745], [0.825, 0.78, 0.81, 0.745, 0.835, 0.81, 0.795, 0.815, 0.82], [0.825, 0.805, 0.835, 0.775, 0.815, 0.805, 0.77, 0.87, 0.805], [0.755, 0.75, 0.74, 0.695, 0.785, 0.76, 0.77, 0.755, 0.72], [0.81, 0.77, 0.81, 0.74, 0.825, 0.825, 0.78, 0.82, 0.765]]\n"
     ]
    }
   ],
   "source": [
    "# Recreate accuracies for NB bc we now use 9 fold\n",
    "compared_models = [\n",
    "    ([(1, 4)], 0), \n",
    "    ([(2, 7)], 0), \n",
    "    ([(1, 4), (2, 7)], 0),\n",
    "    ([(1, 4)], 1), \n",
    "    ([(2, 7)], 1),\n",
    "    ([(1, 4), (2, 7)], 1)\n",
    "]\n",
    "new_nb_accs = list()\n",
    "for i, (model, smooth) in enumerate(compared_models):\n",
    "    accuracies = get_cv_accs(model=model, smoothing=smooth, neg_folds=neg_folds[1:],\n",
    "                                                       pos_folds=pos_folds[1:])\n",
    "    new_nb_accs.append(accuracies)\n",
    "print(new_nb_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svm_bow_accs(cv, train_data, train_targets, test_data, test_targets):\n",
    "    svm_bow = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                              alpha=1e-3, random_state=42,\n",
    "                               max_iter=5, tol=None)),\n",
    "    ])\n",
    "    \n",
    "    parameters = {'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'svm__alpha': (1e-2, 1e-3)}\n",
    "    gs_svm_bow = GridSearchCV(svm_bow, parameters, cv=cv, iid=False,  n_jobs=-1)\n",
    "    gs_svm_bow.fit(train_data, train_targets)\n",
    "    \n",
    "    predicted_bow = gs_svm_bow.predict(test_data)\n",
    "    accuracy = np.mean(predicted_bow == test_targets)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doing CV on SVM BOW: 100%|██████████| 9/9 [06:08<00:00, 40.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82, 0.835, 0.84, 0.78, 0.845, 0.87, 0.82, 0.87, 0.845]\n",
      "0.836111111111111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "svm_bow_accuracies = []\n",
    "for k in tqdm(range(len(train_data_folds_svm)), \"Doing CV on SVM BOW\"):\n",
    "    tmp_train_data = [file for fold in (train_data_folds_svm[:k] + train_data_folds_svm[k + 1:]) for file in fold]\n",
    "    tmp_train_targets = [target for fold in (train_target_folds_svm[:k] + train_target_folds_svm[k + 1:]) for target in fold]\n",
    "\n",
    "    accuracy = get_svm_bow_accs(cv=8, train_data=tmp_train_data, train_targets=tmp_train_targets, \n",
    "                           test_data=train_data_folds_svm[k], test_targets=train_target_folds_svm[k])\n",
    "    svm_bow_accuracies.append(accuracy)\n",
    "print(svm_bow_accuracies)\n",
    "print(np.mean(svm_bow_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing with model ([(1, 4)], 0), 0.8011111111111111 return p value 0.00020803500270744676\n",
      "Comparing with model ([(2, 7)], 0), 0.7505555555555555 return p value 3.68885298917304e-06\n",
      "Comparing with model ([(1, 4), (2, 7)], 0), 0.8038888888888889 return p value 0.0021907762972375403\n",
      "Comparing with model ([(1, 4)], 1), 0.8116666666666666 return p value 0.017415710253860718\n",
      "Comparing with model ([(2, 7)], 1), 0.7477777777777778 return p value 7.841082172473026e-06\n",
      "Comparing with model ([(1, 4), (2, 7)], 1), 0.7938888888888889 return p value 0.0003677259651617817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00, 0.00, 0.00, 0.02, 0.00, 0.00])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Significance testing vs NB\n",
    "\n",
    "bow_nb_p_values = np.zeros(6)\n",
    "for i, model in enumerate(compared_models):\n",
    "    accuracy_nb = new_nb_accs[i]\n",
    "    t, p_val = ttest_rel(accuracy_nb, svm_bow_accuracies)\n",
    "    bow_nb_p_values[i] = p_val\n",
    "    print(\"Comparing with model {0}, {1} return p value {2}\".format(model, np.mean(accuracy_nb), p_val))\n",
    "bow_nb_p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on blind set\n",
    "get_svm_bow_accs(cv=9, train_data=[file for fold in train_data_folds_svm for file in fold],\n",
    "                 train_targets=[target for fold in train_target_folds_svm for target in fold],\n",
    "                 test_data=test_data_svm,\n",
    "                 test_targets=test_targets_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from doc2vec import get_doc2vec_model\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.linear_model import SGDClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_data_folds_d2v = [[simple_preprocess(fl) for fl in fold] for fold in train_data_folds_svm]\n",
    "train_target_folds_d2v = train_target_folds_svm\n",
    "\n",
    "test_data_d2v = [simple_preprocess(fl) for fl in test_data_svm]\n",
    "test_targets_d2v = test_targets_svm\n",
    "\n",
    "assert(len(train_data_folds_d2v) == len(train_target_folds_d2v) == 9)\n",
    "assert(len(test_data_d2v) == len(test_targets_d2v) == 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# doc2vec = get_doc2vec_model()\n",
    "\n",
    "# train_data_d2v = [doc2vec.infer_vector(tokens) for tokens in preprocessed_train_data]\n",
    "# test_data_d2v = [doc2vec.infer_vector(tokens) for tokens in preprocessed_test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# svm_d2v = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42,  max_iter=5, tol=None)\n",
    "\n",
    "# parameters = {'alpha': (1e-2, 1e-3, 1e-4)}\n",
    "# gs_svm_d2v = GridSearchCV(svm_d2v, parameters, cv=9, iid=False,  n_jobs=-1)\n",
    "# gs_svm_d2v.fit(train_data_d2v, train_target_d2v)\n",
    "# gs_svm_d2v.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# predicted_svm_d2v = gs_svm_d2v.predict(test_data_d2v)\n",
    "# acc_svm_d2v = np.mean(predicted_svm_d2v == test_target_d2v)\n",
    "# acc_svm_d2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_predictions(curr_doc2vec):\n",
    "        train_data_d2v = [curr_doc2vec.infer_vector(tokens) for tokens in tqdm(preprocessed_train_data, \"Inferring train vectors\")]\n",
    "        test_data_d2v = [curr_doc2vec.infer_vector(tokens) for tokens in tqdm(preprocessed_test_data, \"Inferring test vectors\")]\n",
    "\n",
    "        svm_d2v = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42,  max_iter=5, tol=None)\n",
    "\n",
    "        parameters = {'alpha': (1e-2, 1e-3, 1e-4)}\n",
    "        gs_svm_d2v = GridSearchCV(svm_d2v, parameters, cv=9, iid=False,  n_jobs=-1)\n",
    "        gs_svm_d2v.fit(train_data_d2v, train_target_d2v)\n",
    "        \n",
    "        print(\"Using alpha {}\".format(gs_svm_d2v.best_params_))\n",
    "        predicted_svm_d2v = gs_svm_d2v.predict(test_data_d2v)\n",
    "        \n",
    "        return predicted_svm_d2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:doc2vec:Attempting to load model_False_100_10_2_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model model_False_100_10_2_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:09<00:00, 190.30it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:00<00:00, 200.42it/s]\n",
      "INFO:doc2vec:Attempting to load model_False_100_20_2_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.845\n",
      "Processing model model_False_100_20_2_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:18<00:00, 98.33it/s] \n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:01<00:00, 103.07it/s]\n",
      "INFO:doc2vec:Attempting to load model_False_100_10_2_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.84\n",
      "Processing model model_False_100_10_2_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:16<00:00, 107.30it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:01<00:00, 112.13it/s]\n",
      "INFO:doc2vec:Attempting to load model_False_100_20_2_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.835\n",
      "Processing model model_False_100_20_2_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_2_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:32<00:00, 54.81it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:03<00:00, 57.49it/s]\n",
      "INFO:doc2vec:Attempting to load model_False_100_10_4_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.82\n",
      "Processing model model_False_100_10_4_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:09<00:00, 189.35it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:01<00:00, 195.99it/s]\n",
      "INFO:doc2vec:Attempting to load model_False_100_20_4_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.85\n",
      "Processing model model_False_100_20_4_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:18<00:00, 97.13it/s] \n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:01<00:00, 101.07it/s]\n",
      "INFO:doc2vec:Attempting to load model_False_100_10_4_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.845\n",
      "Processing model model_False_100_10_4_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_4_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:16<00:00, 106.85it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:01<00:00, 111.44it/s]\n",
      "INFO:doc2vec:Attempting to load model_False_100_20_4_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.815\n",
      "Processing model model_False_100_20_4_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_20_4_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:32<00:00, 55.03it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:03<00:00, 57.72it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_10_2_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.82\n",
      "Processing model model_True_100_10_2_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_0_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:18<00:00, 98.76it/s] \n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:01<00:00, 103.49it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_20_2_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.755\n",
      "Processing model model_True_100_20_2_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_0_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:34<00:00, 51.73it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:03<00:00, 52.27it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_10_2_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.795\n",
      "Processing model model_True_100_10_2_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1.trainables.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_2_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:37<00:00, 48.28it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:03<00:00, 50.94it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_20_2_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.755\n",
      "Processing model model_True_100_20_2_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1.trainables.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_2_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [01:12<00:00, 24.83it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:07<00:00, 26.12it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_10_4_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.76\n",
      "Processing model model_True_100_10_4_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_0_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:26<00:00, 67.55it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:02<00:00, 71.16it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_20_4_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.705\n",
      "Processing model model_True_100_20_4_2_0_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_0_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_0_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [00:50<00:00, 35.35it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:05<00:00, 36.96it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_10_4_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.755\n",
      "Processing model model_True_100_10_4_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1.trainables.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_10_4_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [01:00<00:00, 29.76it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:06<00:00, 29.62it/s]\n",
      "INFO:doc2vec:Attempting to load model_True_100_20_4_2_1_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.695\n",
      "Processing model model_True_100_20_4_2_1_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading syn1 from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1.trainables.syn1.npy with mmap=None\n",
      "INFO:gensim.utils:loading syn1neg from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1.trainables.syn1neg.npy with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_True_100_20_4_2_1_1\n",
      "Inferring train vectors: 100%|██████████| 1800/1800 [02:00<00:00, 14.94it/s]\n",
      "Inferring test vectors: 100%|██████████| 200/200 [00:12<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha {'alpha': 0.01}\n",
      "Got accuracy 0.72\n",
      "Model model_False_100_10_2_2_0_1 got accs \n",
      "\t0.845\n",
      "Model model_False_100_20_2_2_0_1 got accs \n",
      "\t0.84\n",
      "Model model_False_100_10_2_2_1_1 got accs \n",
      "\t0.835\n",
      "Model model_False_100_20_2_2_1_1 got accs \n",
      "\t0.82\n",
      "Model model_False_100_10_4_2_0_1 got accs \n",
      "\t0.85\n",
      "Model model_False_100_20_4_2_0_1 got accs \n",
      "\t0.845\n",
      "Model model_False_100_10_4_2_1_1 got accs \n",
      "\t0.815\n",
      "Model model_False_100_20_4_2_1_1 got accs \n",
      "\t0.82\n",
      "Model model_True_100_10_2_2_0_1 got accs \n",
      "\t0.755\n",
      "Model model_True_100_20_2_2_0_1 got accs \n",
      "\t0.795\n",
      "Model model_True_100_10_2_2_1_1 got accs \n",
      "\t0.755\n",
      "Model model_True_100_20_2_2_1_1 got accs \n",
      "\t0.76\n",
      "Model model_True_100_10_4_2_0_1 got accs \n",
      "\t0.705\n",
      "Model model_True_100_20_4_2_0_1 got accs \n",
      "\t0.755\n",
      "Model model_True_100_10_4_2_1_1 got accs \n",
      "\t0.695\n",
      "Model model_True_100_20_4_2_1_1 got accs \n",
      "\t0.72\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = dict()\n",
    "\n",
    "vector_size = 100\n",
    "dm_concat = 1\n",
    "min_count = 2\n",
    "for dm in [0, 1]:\n",
    "    for context_window in [2, 4]:\n",
    "        for hierarchical_softmax in [0, 1]:\n",
    "            for epochs in [10, 20]:\n",
    "                model_name = \"model_{dm}_{vector_size}_{epochs}_{context_window}_{min_count}_{hierarchical_softmax}_{dm_concat}\".format(\n",
    "                    dm=bool(dm), vector_size=vector_size, epochs=epochs, context_window=context_window,\n",
    "                    min_count=min_count, hierarchical_softmax=hierarchical_softmax, dm_concat=dm_concat)\n",
    "                print(\"Processing model {}\".format(model_name))\n",
    "\n",
    "                tmp_doc2vec = get_doc2vec_model(dm=dm, vector_size=vector_size, context_window=context_window,\n",
    "                                  hierarchical_softmax=hierarchical_softmax, dm_concat=dm_concat, epochs=epochs)\n",
    "\n",
    "                tmp_predicted_svm_d2v = get_predictions(tmp_doc2vec)\n",
    "                tmp_acc_svm_d2v = np.mean(tmp_predicted_svm_d2v == test_target_d2v)\n",
    "                results[model_name] = tmp_predicted_svm_d2v\n",
    "                print(\"Got accuracy {}\".format(tmp_acc_svm_d2v))\n",
    "            \n",
    "for model, predictions in results.items():\n",
    "    print(\"Model {0} got accs \\n\\t{1}\".format(model, np.mean(predictions == test_target_d2v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def permutation_test(predA, predB, targets, R=10000):\n",
    "    correctA = (predA == targets)\n",
    "    correctB = (predB == targets)\n",
    "    og_diff = abs(np.mean(correctA) - np.mean(correctB))\n",
    "    \n",
    "    tmpA = predA.copy()\n",
    "    tmpB = predB.copy()\n",
    "    s = 0\n",
    "    for _ in range(R):\n",
    "        for i in range(len(predA)):\n",
    "            flip = random.randint(0, 1)\n",
    "            if flip == 0:\n",
    "                tmpA[i] = predA[i]\n",
    "                tmpB[i] = predB[i]\n",
    "            else:\n",
    "                tmpA[i] = predB[i]\n",
    "                tmpB[i] = predA[i]\n",
    "        tmp_correctA = (tmpA == targets)\n",
    "        tmp_correctB = (tmpB == targets)\n",
    "        diff = abs(np.mean(tmp_correctA) - np.mean(tmp_correctB))\n",
    "        if diff >= og_diff:\n",
    "            s += 1\n",
    "    return (s + 1 ) / (R + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_False_100_10_2_2_0_1',\n",
       " 'model_False_100_10_2_2_1_1',\n",
       " 'model_False_100_10_4_2_0_1',\n",
       " 'model_False_100_10_4_2_1_1',\n",
       " 'model_False_100_20_2_2_0_1',\n",
       " 'model_False_100_20_2_2_1_1',\n",
       " 'model_False_100_20_4_2_0_1',\n",
       " 'model_False_100_20_4_2_1_1',\n",
       " 'model_True_100_10_2_2_0_1',\n",
       " 'model_True_100_10_2_2_1_1',\n",
       " 'model_True_100_10_4_2_0_1',\n",
       " 'model_True_100_10_4_2_1_1',\n",
       " 'model_True_100_20_2_2_0_1',\n",
       " 'model_True_100_20_2_2_1_1',\n",
       " 'model_True_100_20_4_2_0_1',\n",
       " 'model_True_100_20_4_2_1_1']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_p = sorted(results.items(), key=lambda tup: tup[0])\n",
    "names = [t[0] for t in m_p]\n",
    "preds = [t[1] for t in m_p]\n",
    "accs = [np.mean(t[1] == test_target_d2v) for t in m_p]\n",
    "\n",
    "def helper_print(i, offset):\n",
    "    print(\"{0} and {1}\".format(names[i], names[i + offset]))\n",
    "    print(\"{0} and {1}\".format(accs[i], accs[i + offset]))\n",
    "    print(\"P-val {}\\n\".format(permutation_test(preds[i], preds[i + offset], test_target_d2v)))\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_False_100_10_2_2_0_1 and model_True_100_10_2_2_0_1\n",
      "0.845 and 0.755\n",
      "P-val 0.008599140085991401\n",
      "\n",
      "model_False_100_10_2_2_1_1 and model_True_100_10_2_2_1_1\n",
      "0.835 and 0.755\n",
      "P-val 0.007499250074992501\n",
      "\n",
      "model_False_100_10_4_2_0_1 and model_True_100_10_4_2_0_1\n",
      "0.85 and 0.705\n",
      "P-val 9.999000099990002e-05\n",
      "\n",
      "model_False_100_10_4_2_1_1 and model_True_100_10_4_2_1_1\n",
      "0.815 and 0.695\n",
      "P-val 0.00029997000299970003\n",
      "\n",
      "model_False_100_20_2_2_0_1 and model_True_100_20_2_2_0_1\n",
      "0.84 and 0.795\n",
      "P-val 0.0963903609639036\n",
      "\n",
      "model_False_100_20_2_2_1_1 and model_True_100_20_2_2_1_1\n",
      "0.82 and 0.76\n",
      "P-val 0.067993200679932\n",
      "\n",
      "model_False_100_20_4_2_0_1 and model_True_100_20_4_2_0_1\n",
      "0.845 and 0.755\n",
      "P-val 0.0017998200179982\n",
      "\n",
      "model_False_100_20_4_2_1_1 and model_True_100_20_4_2_1_1\n",
      "0.82 and 0.72\n",
      "P-val 0.0007999200079992001\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09999999999999998"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Algo\n",
    "diffs = []\n",
    "for i in range(8):\n",
    "    helper_print(i, 8)\n",
    "    diffs = [accs[i] - accs[i + 8]]\n",
    "np.mean(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_False_100_10_2_2_0_1 and model_False_100_20_2_2_0_1\n",
      "0.845 and 0.84\n",
      "P-val 1.0\n",
      "\n",
      "model_False_100_10_2_2_1_1 and model_False_100_20_2_2_1_1\n",
      "0.835 and 0.82\n",
      "P-val 0.6028397160283971\n",
      "\n",
      "model_False_100_10_4_2_0_1 and model_False_100_20_4_2_0_1\n",
      "0.85 and 0.845\n",
      "P-val 1.0\n",
      "\n",
      "model_False_100_10_4_2_1_1 and model_False_100_20_4_2_1_1\n",
      "0.815 and 0.82\n",
      "P-val 1.0\n",
      "\n",
      "model_True_100_10_2_2_0_1 and model_True_100_20_2_2_0_1\n",
      "0.755 and 0.795\n",
      "P-val 0.24447555244475552\n",
      "\n",
      "model_True_100_10_2_2_1_1 and model_True_100_20_2_2_1_1\n",
      "0.755 and 0.76\n",
      "P-val 1.0\n",
      "\n",
      "model_True_100_10_4_2_0_1 and model_True_100_20_4_2_0_1\n",
      "0.705 and 0.755\n",
      "P-val 0.14028597140285973\n",
      "\n",
      "model_True_100_10_4_2_1_1 and model_True_100_20_4_2_1_1\n",
      "0.695 and 0.72\n",
      "P-val 0.49865013498650135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Epoch comparison\n",
    "for i in [0, 1, 2, 3, 8, 9, 10, 11]:\n",
    "    helper_print(i, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_False_100_10_2_2_0_1 and model_False_100_10_4_2_0_1\n",
      "0.845 and 0.85\n",
      "P-val 1.0\n",
      "\n",
      "model_False_100_10_2_2_1_1 and model_False_100_10_4_2_1_1\n",
      "0.835 and 0.815\n",
      "P-val 0.34356564343565643\n",
      "\n",
      "model_False_100_20_2_2_0_1 and model_False_100_20_4_2_0_1\n",
      "0.84 and 0.845\n",
      "P-val 1.0\n",
      "\n",
      "model_False_100_20_2_2_1_1 and model_False_100_20_4_2_1_1\n",
      "0.82 and 0.82\n",
      "P-val 1.0\n",
      "\n",
      "model_True_100_10_2_2_0_1 and model_True_100_10_4_2_0_1\n",
      "0.755 and 0.705\n",
      "P-val 0.07879212078792121\n",
      "\n",
      "model_True_100_10_2_2_1_1 and model_True_100_10_4_2_1_1\n",
      "0.755 and 0.695\n",
      "P-val 0.0428957104289571\n",
      "\n",
      "model_True_100_20_2_2_0_1 and model_True_100_20_4_2_0_1\n",
      "0.795 and 0.755\n",
      "P-val 0.11378862113788621\n",
      "\n",
      "model_True_100_20_2_2_1_1 and model_True_100_20_4_2_1_1\n",
      "0.76 and 0.72\n",
      "P-val 0.15758424157584242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Context Window\n",
    "for i in [0, 1, 4, 5, 8, 9, 12, 13]:\n",
    "    helper_print(i, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_False_100_10_2_2_0_1 and model_False_100_10_2_2_1_1\n",
      "0.845 and 0.835\n",
      "P-val 0.7889211078892111\n",
      "\n",
      "model_False_100_10_4_2_0_1 and model_False_100_10_4_2_1_1\n",
      "0.85 and 0.815\n",
      "P-val 0.16698330166983302\n",
      "\n",
      "model_False_100_20_2_2_0_1 and model_False_100_20_2_2_1_1\n",
      "0.84 and 0.82\n",
      "P-val 0.46155384461553844\n",
      "\n",
      "model_False_100_20_4_2_0_1 and model_False_100_20_4_2_1_1\n",
      "0.845 and 0.82\n",
      "P-val 0.39036096390360964\n",
      "\n",
      "model_True_100_10_2_2_0_1 and model_True_100_10_2_2_1_1\n",
      "0.755 and 0.755\n",
      "P-val 1.0\n",
      "\n",
      "model_True_100_10_4_2_0_1 and model_True_100_10_4_2_1_1\n",
      "0.705 and 0.695\n",
      "P-val 0.8788121187881212\n",
      "\n",
      "model_True_100_20_2_2_0_1 and model_True_100_20_2_2_1_1\n",
      "0.795 and 0.76\n",
      "P-val 0.3428657134286571\n",
      "\n",
      "model_True_100_20_4_2_0_1 and model_True_100_20_4_2_1_1\n",
      "0.755 and 0.72\n",
      "P-val 0.3090690930906909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hierarchical softmax\n",
    "for i in range(0, 16, 2):\n",
    "    helper_print(i, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30046995300469953,\n",
       " 0.30086991300869914,\n",
       " 0.298970102989701,\n",
       " 0.31056894310568944,\n",
       " 0.30016998300169984,\n",
       " 0.29527047295270475,\n",
       " 0.28877112288771123,\n",
       " 0.28757124287571245,\n",
       " 0.29017098290170984,\n",
       " 0.29617038296170384,\n",
       " 0.298970102989701,\n",
       " 0.2913708629137086,\n",
       " 0.29287071292870714,\n",
       " 0.3057694230576942,\n",
       " 0.29127087291270876]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare doc2vec to BOW.\n",
    "p_vals = []\n",
    "for i in range(15):\n",
    "    p_vals.append(permutation_test(preds[0], predicted_svm_bow, test_target_d2v))\n",
    "\n",
    "p_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:doc2vec:Attempting to load model_False_100_10_2_2_0_1\n",
      "INFO:gensim.utils:loading Doc2Vec object from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1\n",
      "INFO:gensim.utils:loading vocabulary recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.vocabulary.* with mmap=None\n",
      "INFO:gensim.utils:loading trainables recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.trainables.* with mmap=None\n",
      "INFO:gensim.utils:loading wv recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.wv.* with mmap=None\n",
      "INFO:gensim.utils:loading docvecs recursively from D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1.docvecs.* with mmap=None\n",
      "INFO:gensim.utils:loaded D:\\Projects\\NLP\\models/doc2vec\\model_False_100_10_2_2_0_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between A and B: 0.602531909942627\n",
      "Difference between A and C: 0.5941473841667175\n",
      "Difference between B and C: 0.9414483904838562\n"
     ]
    }
   ],
   "source": [
    "vector_size = 100\n",
    "dm_concat = 1\n",
    "min_count = 2\n",
    "dm = 0\n",
    "context_window = 2\n",
    "hierarchical_softmax = 0\n",
    "epochs = 10\n",
    "\n",
    "doc2vec = get_doc2vec_model(dm=dm, context_window=context_window, hierarchical_softmax=hierarchical_softmax, epochs=10, \n",
    "                            min_count=min_count, vector_size=vector_size, dm_concat=dm_concat)\n",
    "\n",
    "reviewA = simple_preprocess(\"Amazing movie, loved the beginning.\")\n",
    "reviewB = simple_preprocess(\"The beginning was the best part, absolutely spectacular.\")\n",
    "reviewC = simple_preprocess(\"Horrendous movie, hated the ending.\")\n",
    "\n",
    "vectorA = doc2vec.infer_vector(reviewA)\n",
    "vectorB = doc2vec.infer_vector(reviewB)\n",
    "vectorC = doc2vec.infer_vector(reviewC)\n",
    "\n",
    "def vector_diff(a, b):\n",
    "    return np.sum(np.power(a - b, 2))\n",
    "\n",
    "print(\"Difference between A and B: {}\".format(vector_diff(vectorA, vectorB)))\n",
    "print(\"Difference between A and C: {}\".format(vector_diff(vectorA, vectorC)))\n",
    "print(\"Difference between B and C: {}\".format(vector_diff(vectorB, vectorC)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
